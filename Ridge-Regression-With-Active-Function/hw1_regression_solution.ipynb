{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f1b6a1",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed3888f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480614cf",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Loading Data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0887846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data if files don't exist\n",
    "def create_sample_data():\n",
    "    # Create sample data for demonstration\n",
    "    n_samples, n_features = 100, 7\n",
    "    \n",
    "    # Create random training data\n",
    "    X_train = np.random.randn(n_samples, n_features)\n",
    "    true_weights = np.random.randn(n_features)\n",
    "    y_train = X_train @ true_weights + np.random.randn(n_samples) * 0.1\n",
    "    \n",
    "    # Create test data\n",
    "    X_test = np.random.randn(50, n_features)\n",
    "    \n",
    "    # Save to CSV files\n",
    "    np.savetxt(\"X_train.csv\", X_train, delimiter=\",\")\n",
    "    np.savetxt(\"y_train.csv\", y_train, delimiter=\",\")\n",
    "    np.savetxt(\"X_test.csv\", X_test, delimiter=\",\")\n",
    "    \n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "import os\n",
    "\n",
    "data_dir = r\"D:\\Machine Learning from Columbia+\\Module-3\"\n",
    "x_train_path = os.path.join(data_dir, \"X_train.csv\")\n",
    "y_train_path = os.path.join(data_dir, \"y_train.csv\")\n",
    "x_test_path = os.path.join(data_dir, \"X_test.csv\")\n",
    "\n",
    "if not (os.path.exists(x_train_path) and os.path.exists(y_train_path) and os.path.exists(x_test_path)):\n",
    "    X_train, y_train, X_test = create_sample_data()\n",
    "else:\n",
    "    X_train = np.genfromtxt(x_train_path, delimiter=\",\")\n",
    "    y_train = np.genfromtxt(y_train_path, delimiter=\",\")\n",
    "    X_test = np.genfromtxt(x_test_path, delimiter=\",\")\n",
    "\n",
    "lambda_input = int(random.randrange(2**15)%10)\n",
    "sigma2_input = float(random.randrange(2**15)%10 + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecaecfd",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1f484",
   "metadata": {},
   "source": [
    "PART 1: In this part you will implement the $\\ell_2$-regularized least squares linear regression algorithm we have been discussing (ridge regression). Recall from the lectures that this takes the form:\n",
    "\n",
    "$$w_{RR} = \\arg\\min_w \\|y - Xw\\|^2 + \\lambda\\|w\\|^2.$$\n",
    "\n",
    "Your task will be to write code that takes in data $y$ and $X$ and outputs $w_{RR}$ for an arbitrary value of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb44fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution for Part 1\n",
    "def part1(lambda0, X_train, y_train):\n",
    "    d = X_train.shape[1]\n",
    "    temp = lambda0*np.eye(d) + X_train.T.dot(X_train)\n",
    "    wRR = (np.linalg.inv(temp)).dot(X_train.T.dot(y_train))\n",
    "    return wRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b30eece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.84586823,  0.68340145,  0.10772735, -0.79785917,  0.64700549,\n",
       "        0.82833688, -2.29250051])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wRR = part1(lambda_input, X_train, y_train)\n",
    "wRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4e10e",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7532b",
   "metadata": {},
   "source": [
    "In the same code, you will also implement the active learning procedure discussed in Lecture 5. For this problem, we will provide you with an arbitrary setting of $\\lambda$ and $\\sigma^2$ and ask you to provide us with the first 10 locations you would measure from a set $\\mathcal{D} = \\{x\\}$ given a set of measured pairs (y, X). Please look over the slides carefully to remind yourself about the sequential evolution of the sets $\\mathcal{D}$ and (y,X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39288e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution for Part 2\n",
    "def update(lambda0, sigma2, X_train, d, y_train, old_xx, old_xy):\n",
    "    old_xx = X_train.T.dot(X_train) + old_xx\n",
    "    old_xy = X_train.T.dot(y_train) + old_xy\n",
    "    new_var_inv = lambda0 * np.eye(d) + (1 / sigma2) * old_xx\n",
    "    new_var = np.linalg.inv(new_var_inv)\n",
    "    sigma_temp = lambda0 * sigma2 * np.eye(d) + old_xx\n",
    "    new_mean = (np.linalg.inv(sigma_temp)).dot(old_xy)\n",
    "    return new_var, new_mean, old_xx, old_xy\n",
    "\n",
    "def part2(lambda0, sigma2, X_train, y_train, X_test):\n",
    "    d = X_train.shape[1]\n",
    "    active = []\n",
    "    old_xx = np.zeros((d, d))\n",
    "    old_xy = np.zeros(d)\n",
    "    new_var, new_mean, old_xx, old_xy = update(lambda0, sigma2, X_train, d, y_train, old_xx, old_xy)\n",
    "    wRR = new_mean\n",
    "    indices = list(range(X_test.shape[0]))\n",
    "    for i in range(0, 10):\n",
    "        var_matrix = (X_test.dot(new_var)).dot(X_test.T)\n",
    "        row_largest = np.argmax(var_matrix.diagonal())\n",
    "        X_train = X_test[row_largest, :]\n",
    "        y_train = X_train.dot(wRR)\n",
    "        actual_row = indices[row_largest]\n",
    "        active.append(actual_row)\n",
    "        X_test = np.delete(X_test, row_largest, axis=0)\n",
    "        indices.pop(row_largest)\n",
    "        new_var, new_mean, old_xx, old_xy = update(lambda0, sigma2, X_train, d, y_train, old_xx, old_xy)\n",
    "        wRR = new_mean\n",
    "    active = [i + 1 for i in active]\n",
    "    return active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a6de64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 26, 39, 42, 25, 3, 33, 12, 29, 31]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active = part2(lambda_input, sigma2_input, X_train, y_train, X_test)\n",
    "active"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
